\documentclass[a4paper,num-refs]{scr-contemporary}

\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption}
\captionsetup{justification=centering}
\let\mathscr\undefined
\usepackage{newpxmath}
\usepackage{ragged2e}

% Surrey Capital Research Specifics
\jname{Surrey Capital Research} % Set the journal name to Surrey Capital Research

\secondlogo{../images/scr-logo.pdf} % Surrey Capital Research logo
\jlogo{../images/surrey-logo.pdf} % University of Surrey logo


\title{A Deep Dive into Portfolio Optimisation}

\author{\fontsize{12pt}{12pt}\selectfont Riccardo di Silvio, Jack Humphries, Sofiya Kolokolnikova, Freya Cullen, Alex Inskip}

\affil{Surrey Capital Research, University of Surrey}
\papercat{Quantitative Research}

\runningauthor{Surrey Capital Research}

\jvolume{01}
\jnumber{01}
\jyear{2026}

\begin{document}

\begin{frontmatter}
\maketitle

\begin{abstract}
  \justifying
\textbf{Background}:
  Selecting an optimal portfolio allocation across a universe of assets is a central problem in 
  investment management. While mean-variance optimisation, first proposed by Markowitz (1952), provides a 
  theoretically principled framework, its out-of-sample performance has proven disappointing in practice. 
  This study empirically compares four portfolio strategies to assess whether model sophistication translates 
  into superior investment performance. \\
\vspace{0.5mm}
\textbf{Methodology}:
  This study implements and compares four portfolio strategies: equal weight, Markowitz mean-variance, 
  Black-Litterman and Risk Parity applied to an 18-asset UK multi-asset portfolio comprising 15 FTSE 100 equities, 
  a UK government bond ETF, a gold ETC and a broad commodities ETF, over the period January 2015 to December 2025. 
  Strategies are evaluated using a monthly rebalancing framework and assessed across annualised return, volatility, 
  Sharpe ratio, maximum drawdown and portfolio turnover. \\
\vspace{0.5mm}
  \textbf{Results}:
  We find results broadly consistent with DeMiguel et al. (2009), with the naive benchmark 
  proving difficult to displace on a risk-adjusted basis over the full sample period. The optimisation 
  strategies exhibit meaningfully different risk profiles, however, suggesting that Sharpe ratio alone does not 
  fully capture the practical trade-offs between approaches. \\
\end{abstract}

\end{frontmatter}

\begin{keypoints*}
\begin{itemize}
  \item The equal-weight portfolio is robust because it does not rely on 
  estimated parameters and is therefore unaffected by estimation error.
  \item The Efficient Frontier is the set of portfolios that deliver the minimum 
  possible variance for each level of expected return.
  \item Empirical evidence suggests that many optimisation models fail to 
  consistently outperform the equal-weight portfolio out of sample.
\end{itemize}
\end{keypoints*}

\section{Introduction}
\subsection{The Portfolio Allocation Problem}
\indent \indent The portfolio allocation problem is the fundamental question in investment management. 
It asks: How should capital be distributed across available investment opportunities to best achieve 
an investor's objectives? \\
\indent The problem was intractable until 1952, when Harry Markowitz published \textit{Portfolio Selection} in the 
\textit{Journal of Finance} and turned it into a clean optimisation problem, and the “efficient frontier” 
gave investors a principled answer. Markowitz's mean variance model minimises portfolio variance for a given 
level of expected return. It was revolutionary in the consideration of variance as the risk, standing as a 
hallmark of modern portfolio theory. In practice however, the model has proven difficult to implement reliably. \\
\indent Michaud (1989) challenged this view directly, arguing that small estimation errors in expected 
returns produce wildly unstable portfolio recommendations. \\
\indent In 2009, DeMiguel et al. delivered a provocative result: he found that even sophisticated strategies 
incorporating shrinkage estimators and Bayesian methods failed to consistently outperform 1/N out-of-sample, 
suggesting that estimation error dominates theoretical optimality for typical portfolio problems. This tension 
between the theoretical elegance of optimisation and its empirical fragility motivates the present study. 


\subsection{Background and Research Objectives}
\indent \indent This study addresses three main questions:
\begin{enumerate}
    \item Do optimisation models outperform a naive 1/N benchmark
    out-of-sample, applied to a multi-asset UK portfolio over 
    a ten-year period? 
    \item Which model offers the best risk-adjusted performance, 
    as measured by the Sharpe ratio?
    \item How does model performance vary across distinct market
    regimes: the Brexit referendum (2016), the COVID-19 crash (2020),
    and the 2022 rate-hiking cycle?
\end{enumerate}

\subsection{Summary of Findings}
\subsection{Structure of the Report}
\indent \indent The remainder of this report is organised as follows: \newline
Section 2 reviews the theoretical foundations of each model 
and derives their key mathematical results. Section 3 
describes the data, implementation choices, and backtesting 
framework. Section 4 presents the empirical results, including 
full-period performance metrics and a breakdown by market 
regime. Section 5 discusses the findings and their practical 
implications. Section 6 concludes.

\section{Literature and Theoretical Background}

This section details the design of your study, the data used, the models applied, and the analytical framework. 
The goal is to provide enough detail for another researcher to replicate your work.

\subsection{Notation}
Describe the data you used, where you got it from (e.g., Bloomberg, Refinitiv, web scraping), and any steps you 
took to clean, process, or transform it. Mention the time period and frequency of the data.

\subsection{The Equal Weight Puzzle}

The equal-weight (1/N) portfolio assigns an identical weight of 1/N to each asset in the portfolio, holding N assets, regardless of any asset-specific 
characteristics such as return, volatility, or correlation. 
\citet{demiguel_optimal_2009} tested 14 optimisation models across 7 datasets. None consistently outperformed the naive equal-weight portfolio: 
\[
  w_i = \frac{1}{N} \quad \text{for} \quad 1 \leq i \leq N
\]
But why? When expected returns are estimated from historical data in order to determine optimal portfolio weights, the estimates 
improve as more data is collected, but they do so slowly. \newline
Formally, the estimation error decays as
\[
  \hat{\mu} - \mu = \mathcal{O}\!\left(\frac{1}{\sqrt{T}}\right)
\]
where $T$ is the number of observations.

Because the error shrinks at rate $\frac{1}{\sqrt{T}}$, halving the 
error requires four times as much data, meaning that with monthly data 
and realistic return distributions, approximately 500 years of observations 
are required for statistically reliable estimates, especially since these
errors are amplified through the term $\Sigma^{-1}\hat{\mu}$. \newline
\indent The equal-weight portfolio sidesteps this problem entirely: by assigning a fixed weight to each asset, it requires no parameter estimation 
and is therefore immune to estimation error by construction. \newline
The cost of this simplicity, however, is that the portfolio ignores all information about assets' risk and return characteristics, makes 
no attempt to diversify risk efficiently and cannot adapt to changing market conditions.


% ─────────────────────────────────────────────
\subsection{Mean-Variance Optimisation}

\citet{markowitz_portfolio_1952} formulated \textit{Portfolio Selection} as a constrained optimisation problem: minimise 
portfolio variance for a given level of expected return.\newline
Formally:
\[                                                   
  \begin{aligned}
  \min_{\mathbf{w}} \hat{\sigma} =
  \mathbf{w}^\top \hat{\boldsymbol{\Sigma}}\ \mathbf{w}
  \quad \text{s.t.} \quad
  \mathbf{w}^\top \boldsymbol{\mu} = \mu_p
  \quad \text{;} \quad 
  \mathbf{w}^\top\mathbf{1} = 1
  \end{aligned}
\]

with
  $\quad \quad \mathbf{w}, \boldsymbol{\mu} \in \mathbb{R}^N 
  \quad \text{and} \quad
  \hat{\boldsymbol{\Sigma}} \in \mathbb{R}^{N \times  N} \quad \quad$ 
as the vector of portfolio weights, the vector of expected returns with
$\mu_p$ as the scalar target portfolio return and the sample covariance 
matrix of asset returns estimated from historical data respectively. \\

The first constraint, also known as the return constraint, fixes the portfolio to a 
specific point at the target level $\mu_p$, pinning the solution to a specific point on the "Efficient Frontier".
By varying $\mu_p$ across all feasible values, the complete set of minimum-variance 
portfolios - the Efficient Frontier - is traced out.
The second constraint, i.e. the budget constraint, ensures the weights represent a valid
allocation of wealth, hence that the sum of all weights is always equal to $1$. \newline
\indent It is important to note that no domain-restriction condition is imposed on the budget constraint,
each $w_i$ may take any real value, in particular, negative ones.
Practically speaking, a negative weight corresponds to a short position in the associated asset.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{../images/plots/efficient_frontier.pdf}
    \caption{Efficient Frontier estimated using sample covariance}
    \label{fig:efficient_frontier}
\end{figure}

Because the objective function is quadratic and the constraints are linear equalities, we cannot solve the problem by direct substitution 
(two constraints, n unknowns). We therefore use the method of Lagrange multipliers. 
The Lagrangian formulation is:

\[
  \mathcal{L}(\mathbf{w}, \lambda, \gamma)
      = \mathbf{w}^\top \boldsymbol{\Sigma} \mathbf{w}
      - \lambda\!\left(\mathbf{w}^\top \boldsymbol{\mu} - \mu_p\right)
      - \gamma\!\left(\mathbf{1}^\top \mathbf{w} - 1\right)
\]

where $\lambda$ and $\gamma$ are the Lagrange multipliers associated with the return and budget constraints, respectively. 
Intuitively, $\lambda$ captures the marginal cost of requiring a higher return (i.e. how much additional variance must be accepted 
per unit increase in $\mu_p$), and $\gamma$ enforces full investment.

Taking the first-order condition:
\[
  \frac{\partial \mathcal{L}}{\partial \mathbf{w}} = 2\boldsymbol{\Sigma} \mathbf{w} - \lambda \boldsymbol{\mu} - \gamma \mathbf{1} = \mathbf{0}
\]

Solving gives:
\[
  \mathbf{w}_p = \frac{\lambda}{2}\,\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu} + \frac{\gamma}{2}\,\boldsymbol{\Sigma}^{-1}\mathbf{1}
\]

Imposing the budget and return constraints leads to the following two-fund theorem: all efficient portfolios can be expressed as a 
linear combination of any two distinct efficient portfolios.
\[
  \mathbf{w}_A = \frac{\boldsymbol{\Sigma}^{-1}\mathbf{1}}{\mathbf{1}^\top \boldsymbol{\Sigma}^{-1}\mathbf{1}}
  \qquad
  \mathbf{w}_B = \frac{\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}}{\mathbf{1}^\top \boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}}
\]

Note that $\mathbf{w}_A$ is the \emph{global minimum variance} (GMV) portfolio, 
the leftmost point on the efficient frontier, obtained by dropping the 
return constraint and minimising variance subject only to full investment:
\[
  \mathbf{w}_{\mathrm{GMV}}
    = \frac{\boldsymbol{\Sigma}^{-1}\mathbf{1}}{\mathbf{1}^\top \boldsymbol{\Sigma}^{-1}\mathbf{1}}
\]

The \emph{maximum Sharpe ratio} portfolio is:
\[
  \mathbf{w}_{\mathrm{MSR}}
    = \frac{\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu} - r_f \mathbf{1})}
           {\mathbf{1}^\top \boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu} - r_f \mathbf{1})}
\]
Despite its theoretical elegance, Markowitz optimisation suffers from a well-documented problem. 
As mentioned above, the solution depends critically on $\boldsymbol{\mu}$ and $\boldsymbol{\Sigma}$, both estimated from historical data. \newline
\indent Small errors in $\mathbf{\mu}$ can cause large shifts in optimal weights.
\citet{michaud_markowitz_1989} characterised the optimiser as an "error maximiser": it systematically overweights assets with 
overestimated returns and underestimated variances.
\paragraph{The problem in practice.} Despite its theoretical elegance, Markowitz optimisation suffers from a well-documented problem. As mentioned above, the solution depends critically on $\boldsymbol{\mu}$ and $\boldsymbol{\Sigma}$, both estimated from historical data. Small errors in $\boldsymbol{\mu}$ can cause large shifts in optimal weights. \citet{Michaud 1989} characterised the optimiser as an ``error maximiser'': it systematically overweights assets with overestimated returns and underestimated variances.


% ─────────────────────────────────────────────
\subsubsection{Black–Litterman Model}

\paragraph{Origins} The Black-Litterman (BL) model was developed by Fischer Black and Robert Litterman at Goldman Sachs in the early 1990s \citep{Black1990, Black1992} to address the instability of Mean-Variance Optimisation.

\paragraph{Key insight.} The BL model addresses two shortcomings of classical optimisation. First, what should the expected returns be when the investor has no particular view (a quantified belief about the future return of an asset or spread)? Rather than relying on noisy historical data, BL uses returns implied by current market-capitalisation weights as the natural neutral starting point. Second, how should an investor's views be incorporated in a consistent and controlled way? BL offers a formal Bayesian framework for blending subjective views with this equilibrium prior, weighting each by its precision.
The equilibrium prior anchors the portfolio near market weights, ensuring diversification even in the absence of views. When views are expressed, the portfolio tilts away from equilibrium only as far as the investor's confidence warrants. The investor retains full control over the scope, direction, and confidence of each view, making the construction process transparent.

\paragraph{Step 1: Equilibrium Returns}

The BL model takes as its starting point the equilibrium expected returns implied by observed market-capitalisation weights. Assuming the market portfolio is mean-variance efficient, the equilibrium excess returns are:
\[
\Pi = \delta \Sigma w_{m}
\]
where $w_m$ is the market-capitalisation weight vector, $\Sigma$ is the covariance matrix of asset returns and $\delta$ is the risk-aversion coefficient:
\[
  \delta = \frac{r_m - r_f}{\sigma_m^2}.
\]

\paragraph{Step 2: Express Views}

As mentioned above the BL model allows the investor to express views. A view can be absolute ("asset A will return 5\%") or relative ("asset A will outperform asset B by 2\%"). Each view has two components: the expected return itself, and a confidence level attached to it.
Formally, K views are expressed through the system:
\[
  P\mu = Q + \varepsilon, \qquad \varepsilon \sim \mathcal{N}(\mathbf{0}, \Omega),
\]
where
\begin{itemize}
  \item $P \in \mathbb{R}^{k \times n}$: the \emph{pick matrix} (which assets are involved),
  \item $Q \in \mathbb{R}^k$: the expected view returns,
  \item $\Omega \in \mathbb{R}^{k \times k}$: view uncertainty (diagonal),
  \item $\varepsilon$ (error-term): the deviation of true returns from the stated views, assumed to be normally distributed with mean zero.
\end{itemize}

The views incorporated in this study are motivated by the momentum effect documented by \cite{Jegadeesh1993}. They show that stocks with high returns over the prior 3--12 months continue to outperform stocks with low prior returns over the subsequent 3--12 months, generating abnormal returns of approximately 1\% per month. This persistent pattern offers an empirically grounded basis for constructing views within the BL framework.

Assets are ranked by their return over the previous 12 months, excluding the most recent month to eliminate short-term reversal effects. The highest-return decile forms the winner portfolio, while the lowest-return decile constitutes the loser portfolio. The view is expressed as:

\begin{equation}
    p_{k}^{\top}\mu = q_k
\end{equation}

$\mathbf{p}_k$ assigns equal positive weights to winner assets and equal negative weights to loser assets, forming a long--short, dollar-neutral momentum view. The expected return spread $q_k$ is calibrated to the momentum premium documented by \cite{Jegadeesh1993} or estimated over a rolling window. Views are updated at each rebalancing date as rankings change.

The Lagrangian formulation yields an unconstrained solution that permits short-selling (negative weights). This study focuses exclusively on long trades: only views with positive expected returns ($q_k > 0$) are retained, and portfolio weights are constrained to $w_i \geq 0$ at the optimisation stage.


\paragraph{Step 3: Bayesian Update}

The prior on expected returns is:

\begin{equation}
    \mu \sim \mathcal{N}(\Pi, \tau \Sigma)
\end{equation}

This encodes the belief that expected returns are centred on the equilibrium vector $\boldsymbol{\pi}$, with uncertainty scaled by $\tau$. Combining this prior with the view system via Bayes' theorem yields the posterior distribution over expected returns:

\begin{equation}
   \mu \mid Q \sim \mathcal{N}(\mu_{\mathrm{BL}}, \Sigma_{\mathrm{BL}})
\end{equation}

where the posterior mean is:

\begin{equation}
    \mu_{\mathrm{BL}} = \left[(\tau \Sigma)^{-1} + P^{\top}\Omega^{-1}P\right]^{-1}\left[(\tau \Sigma)^{-1}\Pi + P^{\top}\Omega^{-1}Q\right]
\end{equation}

The posterior mean $\boldsymbol{\mu}_{\text{BL}}$ is a precision-weighted average of the equilibrium prior $\boldsymbol{\Pi}$ and the investor's views $\mathbf{Q}$, with each source weighted inversely by its uncertainty. When views are diffuse (large $\boldsymbol{\Omega}$), $\boldsymbol{\mu}_{\text{BL}}$ remains close to $\boldsymbol{\Pi}$ and the portfolio stays near market weights. If the views are held with high confidence (small $\boldsymbol{\Omega}$), $\boldsymbol{\mu}_{\text{BL}}$ tilts toward $\mathbf{Q}$. This blending property is central to the appeal of the BL framework: the investor's views are incorporated gradually and in proportion to their confidence, rather than overriding the prior entirely.

\paragraph{Step 4: Portfolio Optimisation}

The posterior mean $\boldsymbol{\mu}_{\text{BL}}$ is used in place of the sample mean in the mean–variance optimisation. The optimal portfolio is obtained by maximising the Sharpe ratio over the feasible set $\mathcal{W}$:

\begin{equation}
    \mathbf{w}_{\text{BL}} = \arg\max_{\mathbf{w} \in \mathcal{W}} \; \frac{\mathbf{w}^{\top}\boldsymbol{\mu}_{\text{BL}} - r_f}{\sqrt{\mathbf{w}^{\top}\boldsymbol{\Sigma}\,\mathbf{w}}}
\end{equation}

Because $\boldsymbol{\mu}_{\text{BL}}$ blends market equilibrium with the investor's views, the resulting portfolio $\mathbf{w}_{\text{BL}}$ only moves away from market weights when the investor has strong, meaningful views. In areas where views are weak or uncertain, the portfolio stays close to the market and remains broadly diversified.


\subsection{Black-Litterman and its Bayesian approach}
If you are testing a strategy, describe the backtesting framework. Mention key parameters like rebalancing 
frequency, transaction cost assumptions, and performance metrics used.

\subsection{Dalio's Risk Parity}


\section{Methodology}

\subsection{Data}

\subsection{Model Implementation}


\subsection{Backtesting Framework}
Backtester method


\subsection{Performance Metrics}
All metrics we're using
(Return, Sharpe, Sortino, Volatility, CAGR, Max DD, VaR, CVaR)

\section{Results}
This section presents the key findings from your analyses and interprets their significance. Use figures and tables to 
present your results clearly.

Present your main results. This could be in the form of tables summarizing statistical outputs, or charts showing trends and relationships.


\subsection{Main Result: Performance Comparison}

Discuss what your results mean. How do they relate to your initial research question? Are they consistent with existing literature? What are the implications of your findings?


\subsection{Risk-Return Trade-off}


\subsection{Regime Dependence}


\subsection{Portfolio Characteristics}


\section{Discussion}
Summarize the main conclusions of your research. Reiterate the key insights and their importance.


\subsection{Why did 1/N perform well?}


\subsection{The risk parity puzzle}


\subsection{Practical Implications}



\subsection{Limitations}


\section{Conclusion}



\section{Declarations}
Briefly describe the contribution of each author to the research and writing of the report. For example: "A.B. designed the research. C.D. collected the data. E.F. performed the analysis. All authors contributed to writing the report."



Future work could include:
\begin{itemize}
    \item Exploring alternative methodologies or datasets.
    \item Addressing limitations of the current study.
    \item Expanding the research to a different market or asset class.
\end{itemize}


\begin{table}[bt!]
\caption{Descriptive caption for your table.}\label{tab:example_table}
\begin{tabular}{l c c c}
\toprule
Category & Metric 1 & Metric 2 & Metric 3 \\ 
\midrule
Group A & 0.00 & 0.00 & 0.00 \\ 
Group B & 0.00 & 0.00 & 0.00 \\ 
Group C & 0.00 & 0.00 & 0.00 \\ 
\bottomrule
\end{tabular}

\begin{tablenotes}
\item Note: Explain any specific details about the data in the table.
\end{tablenotes}
\end{table}

\bibliography{../refs/refs}

\end{document}
